A NEW DESIGN AND ALGORITHM FOR LENTICULAR LENSES DISPLAY(/section)René de la Barré, Roland Bartmann, Mathias Kuhlmey, Bernd Duckstein, Silvio Jurk, Sylvain Renault(/section)2016 International Conference on 3D Imaging (IC3D)(/section)In this study, a novel autostereoscopic 3D display design based on our patent specification is proposed and demonstrated. In contrast to common autostereoscopic two- view-designs with lenticulars, our approach allows more distance between image splitter and display panel. In comparison to 3D displays showing details at nominal distance, our design projects the images to a near zone in front of the display. As a consequence, the low magnification factor reduces distance errors from relative movements of display panel and image splitter. An image processing algorithm was developed to arrange the content and correct display shortcomings of image allocation caused by optical properties of the lenticulars. In addition, this algorithm allows static adjustment and tracking of observer position in a defined area in front of the display. We integrated the display in a production chain for digitalization and presentation of cultural heritage objects and developed special web-based modules for stereo rendering and user interaction, so that observers may explore cultural content in a natural manner.(/section)1. INTRODUCTIONToday, new desktop and tablet displays show a highly increased resolution. This is an advantage for the design of autostereoscopic displays (ASD). ASD need several interleaved images and with such a high overall resolution it is possible to reproduce a good single view resolution, as well. Due to smaller subpixel structures, the image splitter needs a reduced lens pitch as well as increased accuracy when aligning with the LC-panel. By getting the image splitter as close as possible to the display structure, some properties of image separation are unfavorable. The influence of distance flaws will be increased. The smaller distances affect the lenticular pitch and thereby optic aberrations like the Petzval field curvature [1, 2]. Due to the latter, the quality of the stereo image deteriorates with a wider observing angle. A design approach to reduce angle dependence and panel waviness is an increase of lenticular lens radius. This is familiar from the patent literature [3]. The concept is based on a smaller magnification factor of the proposed 3D system. Thereby the stereo image is composed by several different image strips.Also quite important for perception of good 3D images is the delivered depth. Our novel 3D display can show more depth than conventional flat autostereoscopic designs with smaller lenticulars. The presented depth of an autostereoscopic panel is proportional to the lens pitch [4]. Therefore, the proposed design is equipped with an image splitter with comparatively large lens pitch in the millimeter range. That concept of lower magnification was already used for ASD design [5]. It is significant different to the traditional design approaches known from literature [6].We implemented the idea of aerial-image representation. The intermediate image in the so called air-image plan can be made visible by a physical plane for instance a simple sheet of paper. To get such kind of image, the matrix pixel plane has to be located somewhere between simple and double focal point distance of the lenticular. The 3D model, image algorithms, optic simulations and experimental validation of the novel two-view ASD design will be presented.To bring out the quality of the 3D display, we integrated it in a content production chain for cultural heritage objects combining different scanning techniques, computer graphic methods and 3D web rendering tools. Such models are mostly complex and should be visualized with a lifelike level of details. Additionally, we developed a web compatible display driver and appropriate interaction modules in JavaScript and HTML for the Fraunhofer IGD renderer x3dom, a web-based library allowing a seamless integration of 3D content into a webpage [7].2. DISPLAY MODELConventional ASD are often multi-layered flat panel designs. Our novel air-image setup is also based on the lenticular image splitter type. The lens grid separates the stereo strips in the pixel plane of the display. In contrast lenticular parameters and distances are different from the majority of common designs and the underlying principle is described in detail in former literature [3].The geometric conception of the proposed 3D display is depicted in Fig. 1. Different light paths of an exemplarily chosen stereo image section are shown. In detail, several subpixels of the matrix panel MP are emitting light rays of displayed image content to the observer eyes. All image strips b will be projected as optical air-image in AP through a vertical aligned cylindrical lens array BS. The projected air-image consists of different B sections.978-1-5090-5743-6/16/$31.00 ⃝c2016 IEEE  Fig. 1. Top view scheme of the air-image display with red for left and green for right content, light ray distribution from an exemplary part of matrix pixel panel MP through the image splitter BS to the eyes position (at the middle of projection width C in distance P) in nominal plane NP; b is a single image strip in MP and B the projection in the air plane AP; A, a and D are different distances between AP, BS, MP and NP.However, optical imaging of real objects is applicable for cylindrical lenses only at the perpendicular profile of cylinder axis [1]. The human eye is able to dim the resulting image intensity and therefore able to separate a single view direction-dependent. The eye pupil of the observer in nominal plane NP selects images in viewing direction out of a variety of stacked projected images in AP and provides a comparable sharp image perception. In our model, stereo sections are calculated based on the geometrical stripe width and distance parameters. For the eye, only image areas are visible inside connection line between the eye pupil periphery and the edge regions of the cylindrical lenses. These sections B in the geometric scheme in Fig. 1 are projections of left and right image content of strips br and bl. The allocation of the single image stripes is depicted in detailinFig.2.q=  P (3)  Fig. 2. Magnified part of image splitter BS and matrix pixel plane MP with red for left and green for right content, different stripe sections and distances are depicted.The image segments b, equals the image strip pair bl and br, are dependent on the ratio of air plane AP and image splitter BS to matrix plane MP. From condition a < A follows b < B with magnification factor ß, see equation (2).b = ß B and ß=  (2) In MP the distance of the center sections bl and br will be defined as q in equation (3). Thus parameter q is proportional to distance a between BS and MP. In equation (4) the periodical block distance Q of one image strip pair to another is the projection of lens pitch L from single eye to matrix plane with q << P.Q = L   +   (4)   Furthermore the block distance Q is approximately equal to lens pitch L. The gap between two image strips will be defined by parameter s in equation (5) and is dependent on the ratio of distances a and D.s=q−b (5) B = L    −   (1)g  = ⋅ Q−q  −b ,i=1...4 (6)  =s− ⋅g (7)Then the subdivision of s in smaller gaps is depicted in Fig. 2 and equation (7). The parameters gi equal to reserve sections 1 to 4, see equati on (6), are symmetric and of the same value here. Resulting from the equation (1), the strip width B of projected air-image sections is smaller than lens pitch L. In detail, it is inverse proportional to air-image distance A.Thus the gaps between image strips b will rise by increasing the air-image distance A.The distances and widths determined by equation (1) to (7) are dependent on different geometric parameters L, A, a, D and P. The first three L, A and a are defined by the arrangement of the 3D display and therefore once set, they are constant. The distance D in contrast is dependent on the current position of the observer and P on the interpupillary distance of the observer’s eyes. This results in a change of the widths B and b. The gap sections Δ and gi need to be updated by tracking the observer when he changes his distance to the screen.3. IMAGE PROCESSINGA well-known optical purpose of a lenticular array BS in a 3D display is to magnify and split the image information on the pixel plane MP. Thus, it separates the views to eye positions of the observer in NP. A common approach is to get an arrangement, where each lenticular lens magnifies a group of subpixels. By using an exemplary lens pitch of eight subpixel widths, the observers are able to look at up to eight different images. For such a case the allocation of subpixels with appropriate content information decides whether it is used as a single user or multiview system. As another detail, the pixel panel is not exactly located in the focal point. Because of angle dependent aberration effects and unwanted image strip enlargements, the pixel plane MP will be arranged close to the focus of the lenticular lenses.In our case MP lies behind the focal plane of the lenticular lenses, therefore more than one subpixel in its width will be captured.3.1 Image generationThe image allocation used for image stripe arrangement will be explained in detail, see Fig. 3. These sections are described as bl and br and will be reproduced, laterally reversed on stereo image layer AP. Therefore, the observer only sees a partial section of width b. Inside range c it is possible to locate N pixels and therefrom in section b a subset of it. For the case that the observer distance to the display will be changed, the pixels in an image strip shift from visible areas to invisible areas and vice versa. Meanwhile the observer is still looking at an undisturbed image. Because the width of reserve sections gi is dependent on the change of distance to the panel.The parameter N is the number of all subpixels for a display row, where Q is the number of subpixels for each content block with the index is. The parameter x describes the subpixel address in x-direction for each display row. The variable indices r and l represent right and left content for the respective eyes of the observer. Finally, reserve sections g1 to g4 are currently invisible areas. The basic idea of the algorithm is that with different strip widths br and bl the image information needs to be scaled too. The image information will be distributed over the whole number of subpixels.However, the section size for lateral movements can be increased by tracking. Then the observer position will be captured and thus affects the allocation of pixels for each image strip. In addition distance changes can be adapted by z-tracking.f Fig. 3. Schematic, representation of a horizontal pixel row segment in MP (front view), image stripes bi and reserve sections gi, uniform block width Q and resolution N.The arrangement requires a new interleaving pattern and the use of a standard side-by-side stereo image format. This image format has to be converted internally in horizontal anamorph images with a side ratio of approximately 1:3. In our experimental setup, see further details in chapter 4, we used a magnification ratio of 1:2.4. The image has to be divided in stripes that partially overlap. Therefore, redundant information will be inscribed in the peripheral image stripe areas. The position of the stripes inside the partial image can be changed dynamically by controlling the interleaving parameters through a tracking signal. This will enable stereo image adaptation to the tracked observer position. 3.2 Image algorithmIn mathematical terms, the algorithm implements atransformation of pixel coordinates from an initial imagewith horizontal resolution N0 to converted pixel coordinatesdisplay is th e zero point for the x-coordinate, angle  of the used image for the 3D display. The edge point of thedescribes the viewing angle. A source image with a givencoordinates     ,    of an image composed by image strips  , horizontal resolution N0 will be converted to pixelthat are merged together in a different order, see equation (8). The resolution of right and left image has to be the same. Otherwise we have to scale it to the same resolution.     ,  =   ⋅[ +  + h   ±    ⋅  ⋅ ] (8)  ,              This equation is the mathematical representation of that coordinate transformation where x’ is the x-coordinate of the source image for left or right image. The value N0/N describes a resolution ratio. Furthermore, xs is a shift value that represents the slope of the grid and also includes the observer position dependent on a tracking value. This value influences the x-position of the image. A tracking of the observer distance will be realized by changing the parameter Q. Equation (4) shows this relation. The value h(x) as block position in equation (9) describes a coordinate mapping within one block. If x is at the right section of content information then Q0 = 0 and if x is at the left section then Q0 = Q/2. + h    =    −             ⋅   (9)Fig. 4. Exemplarily chosen single lens for simulation of angle dependent light ray distribution between BS and MP, Focal plane FP and Petzval field curvature are depicted, viewing image stripe width is proportional to viewing angle.The width of the image stripes in MP is angle dependent. Hence the observer in viewing distance D perceives different image stripe widths from respective viewing directions. For the experimental setup from Tab. 1 the viewing angle is in the range from 0 to 14°. The stripe width will be increased due to wider viewing angle and more distance to the focal point of a single lens element. The reasons for that are aberration effects or simplified the Petzval field curvature due to inclined incidence of light [8]. Fig. 4. shows the angle dependent stripe width by use of the optical simulation software OpticstudioTM. For specific arrangements or 3D display setups the relation between angle and strip width has to be investigated in detail. The parabolic dependence of stripe width from viewing angle and wavelength is depicted in Fig. 5. The results were determined by optical simulations and the weighted average data was mathematically fitted by a parabola. Function b(α) in equation (10) describes that angle dependency, where c0, c1 and c2 represent the constants of regression. In addition to equation (8), the disparity value d results from position change of image left against image right. F and b(α) describe the required scaling factors to corresponding pixel positions of the original image. The scaling compensation factor F corrects the offset error. Function b(α) is angle dependent and results from a correction of strip enlargement by an increased observation angle α that will be described in detail in the following chapter.3.3 Light ray simulation and error correctionThe image processing algorithm was tested and validated by optical modeling software and in the experiment; the used parameters, with pixel pitch p, are listed in Tab. 1.Tab. 1. 3D display simulation parameters    Parameter Value  Unit  P 65 Mm  D 1,2 M  a 69,5 mm  f 53,8 Mm  p 0,11655 mm  N 5120 Pixel         Lenticular arrayVisualizing screenIn common autostereoscopic lenticular lenses displays the dimmed stereo image by eye aperture is directly composed on the image splitter plane BS. In contrast, the proposed novel 3D display depicts a real air-image in front of the lenses array at AP composed of stereo image stripes.MP BSFP APFig. 7. Horizontal light distribution with alternating colored strips in several distances to image splitter BS and pixel plane MP, anterior focal plane FP is barely visible; RGB- pattern is sharply separated in 17 cm distance from BS at air-image plane AP.However, to prove the projection of the air-image a RGB- test image with three respectively different colored image stripes was created by our adapted image allocation algorithm. All image sections br were filled with one equally      Fig. 5. Adaptation of Petzval field curvature, wavelength and angle dependent strip width in pixels was derived from optical simulation data and fitted by a parabola curve.Fig. 6. 3D display setup with test content.4.2 Proof of air-image/stripe distribution     =      +     +      (10)The parameters for average adaptation of the Petzval field curvature were c0 = 12.5, c1 = 0.206 and c2 = 0.045. The angle α respects the viewing position in front of the display. Therefore, the correction is realizable for tracking as well. The position of the observer can be transformed into this angle. The depicted adaption in Fig. 5 limits the possible viewing space by its range and the feasible maximum stripe width. The application of the proposed strip width adaptation is shown in the image presentation in chapter 4.4. EXPERIMENT, RESULTS AND APPLICATIONAn autostereoscopic air-image 3D display was developed and examined by using a 5K panel with a large-sized lenticular lens grid.4.1 Display setupThe 27” 3D display mock-up was realized on a test carrier with micro meter drives for distance adjustments. In Fig. 6 the display setup consisting of a vertical lenticular array and a matrix panel in landscape format is depicted. An additional reflecting screen for visualizing of light ray paths was attached too. The used display was a DELL UP2715K and the lenses raster plate was produced in resign on glass technology. The cylindrical lenses have a pitch of L = 5.91 mm. For the display control a Windows 8 PC (ASUS ROG G20AJ-DE045S) with an NVidia 980 GTX graphics card was applied. A GPU based software render tool developed by Fraunhofer HHI was used for image processing and content multiplexing. The algorithm used the acceleration of DirectX11 libraries to generate the displayed pattern. For the documentation of results a CANON EOS-1 Ds Mark II camera and contrast enhancement software were used.          distributed RGB-stripe. The emerging ray picture was visualized on a white screen, shown in Fig. 7. In different distances to BS, several centimeters away from focal plane FP, the color distribution is changing. The best color separation was provided by the real air-image in 17 cm distance at air-image plane AP. The perceived RGB-image is merged correctly in that distance only. The RGB-stripe pattern presents either the left or right view of the stereo image. It was demonstrated that periodical superimpositions with alternate changing colors exist in the projected light field.4.3 Presentation of stereo images floating in airFig. 8. Mock-up of the 3D display showing content from Fraunhofer cultural heritage project. The view is assembled from the overlapping image stripes.To operate and test the new 3D display, we implemented new rendering modules and used scanned objects created by the Fraunhofer cultural heritage project. The main objective of this current project is to create a processing chain for the digitalization and the presentation of cultural objects as sculptures, statues and parts of historical monuments, into consideration on their different materials (sandstone, marble, wood etc.). These objects are very suitable to bring up the stereo capabilities and quality of the display because they have complex forms and contain important details that have to be presented in a lifelike manner. In general, digitalization can be done by scan sensors (new methods are developed and tested in the project) as well as by 3D reconstruction algorithms for static objects and dynamic bodies [9].Fig. 8 shows first results of scanned objects viewed on the new display and rendered in real-time inside an interactive webpage, here in full screen mode (from left to right: „Kreuzblume“ by Fraunhofer IPM and Münster Freiburg; „Terracotta Krieger“ and „Dave“ by Fraunhofer IGD). To render the scene in stereo and process user interaction as body gesture, we created some JavaScript and HTML extensions in the x3dom library.Fig. 9. Magnified image section of Fig. 8, on the left side without and on the right side with applied correction algorithm for image stripes (1-8).Special display drivers and tracking modules for head and hand tracking were implemented and tested. Interactive web-based 3D scenes for suchlike auto-stereo displays can be done in an efficient way. The content shown in Fig. 9 was rendered via the extended library and processed by image allocation and correction algorithms described in chapter 3. The two pictures demonstrate the differences in the image strip alignments. In table 2, N0 describes the resolution of the source image shown in Fig. 8 where N is the resolution of the pixel panel.Tab. 2 Constant input parameters of the proposed image processing algorithm equation (8) for Fig. 8 and 9.The values Q and s depend on the viewing distance and system parameters of the 3D display. Due to the chosen setup the slope angle of the grid is zero. The central camera position is fixed in front of the panel, therefore xs is constant zero. In addition, the disparity value d is zero because there is no shift between the images. The parameter Q0 is zero due to the block position for the right views. F as compensation factor results from calibration to improve the image quality.Tab. 3 Parameter comparison of variable values in pixels by stripe numbers shown in Fig. 9.     N0 NQ  s xsd  Q0  F  1920 512053,67  9 00  0 1,17 pixel pixelPixel  pixel pixel pixel  pixel       No.  12  3 45  6 7  8 x  43734427  4480 45344588  4641 4695 4749α   10,010,3  10,6 10,911,1  11,4 11,7 12,0 h(x)  0,80,5  1,2 0,80,5  1,2 0,8 0,5b(α)   19,119,4  19,7 20,020,4  20,7 21,1 21,5 xr’(x,α)  16461666  1687 17071726  1747 1767 1786 xr’(x,0)  16501670  1691 1710 1730   1751  1771  1790       The results shown in Tab. 3 exemplarily demonstrate the enlargement of the visible image stripes 1 to 8. In detail the angle dependent correction of b(α), see Fig. 5, and xr’(x,α) was used. However, the selected area in the image is almost linear and the difference to xr’(x,0) is about four pixels.5. SUMMARY 5.1. Discussion of resultsFor this considered single user approach, with a magnification of 2.4:1, a plurality of pixels will be covered by one lens for each row. Several content-dependent subpixels are joined together to constitute an image stripe either related to the left or right observer eye. Invisible from the current observer position, adjacent subpixels ensure reserve zones and allow a wider viewing space. Light rays from the intermediate image in the projection plane were selected by eye aperture. Thus, the observer will perceive a 3D stereo image with good quality and depth.Compared with conventional 3D display designs of 100- times magnification and column multiplexing, it is a lot easier to adjust display matrix and lens grid. The influence of display waviness and distance errors of lens grid and panel are minimized. For the experiment a non-corrected lens grid with wide cylindrical lenses was used. It could be proven that the used image processing algorithm allows the dynamic correction of the arrangement and optical errors.The perceptible displayed resolution is defined by the distance-dependent magnification. Compared to the observing position a tracking is necessary for representation of image content with no delay.Then, the stereo image will be continuously adjusted by the position of the user’s head. The scene will be explored from different perspectives while the observer moves laterally in front of the display. Furthermore, the user will be able to interact with the virtual content via gesture in a natural manner (e.g. for rotation, selection, etc.) because virtual objects float in the air, close to him.5.2. ConclusionA new approach for designing two-view ASD was presented. The effects of this design were discussed. Therefore an optical ray tracing model and various image processing algorithms were developed and tested by simulation and experiment. It was proven that a real 3D image with high quality and low magnification is feasible. The low image magnification reduces the influence of misalignment errors between display screen and lenses raster on the viewing quality. Then the enhanced distance is large compared to the waviness of the display panel.The substrate layer for the lenses creates only low intra ocular crosstalk effects. Furthermore the perceptible 3D depth is increased, compared with common 3D displays.The integration of the display and software modules in a production chain for digitization and presentation of museum and cultural objects demonstrates well the feasibility of the techniques. Now, with this web-based solution (x3dom renderer and extensions) 3D content can be presented on such stereo displays over the internet, lifelike, with a high fidelity and depth. Thus, the floating object close to a museum visitor tempts him to interact with it. Of course, the interactive stereo display can also be used for other scenarios e.g. for automotive, construction and medical applications as well as for gaming or entertainment.6. ACKNOWLEDGEMENTWe would like to thank the Münster Freiburg as well as the Fraunhofer IPM and IGD for the provided image content. Financial support by Fraunhofer-Gesellschaft, Munich (grant no. 6   96) is gratefully acknowledged.(/section)http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823447(/section)@INPROCEEDINGS{7823447, author={R. de la Barré and R. Bartmann and M. Kuhlmey and B. Duckstein and S. Jurk and S. Renault}, booktitle={2016 International Conference on 3D Imaging (IC3D)}, title={A new design and algorithm for lenticular lenses display}, year={2016}, pages={1-7}, keywords={lenses;object detection;optical design techniques;optical images;stereo image processing;three-dimensional displays;Web-based modules;autostereoscopic 3D display design;autostereoscopic two-view-designs;cultural heritage object digitalization;cultural heritage object presentation;image processing algorithm;image splitter;integrated optics;lenticular lens display;stereo rendering;user interaction;Image resolution;Lenses;Mathematical model;Observers;Optical imaging;Strips;Three-dimensional displays;3D display design;3D visualization;air-image;autostereoscopic;lenticular;low crosstalk;x3dom}, doi={10.1109/IC3D.2016.7823447}, month={Dec},}