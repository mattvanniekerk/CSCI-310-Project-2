PERCEIVED QUALITY OF ANGULAR RESOLUTION FOR LIGHT FIELD DISPLAYS AND THE VALIDY OF SUBJECTIVE ASSESSMENT(/section)Peter A. Kara, Maria G. Martini, Peter T. Kovacs, Sandor Imre, Attila Barsi, Kristof Lackner, Tibor Balogh(/section)2016 International Conference on 3D Imaging (IC3D)(/section)Angular resolution plays a vital role in the perceived quality when displaying visual content on autostereoscopic 3D displays, since it affects the motion parallax effect. In this paper, we present the results of a subjective quality assessment carried out on a light field display, investigating the perceptual quality of visual content with different angular resolutions. We also address the question of subjective assessment validity, since the visual experience of suboptimal, reduced angular resolution is currently a completely new phenomenon for test participants.(/section)Quality of Experience, Perceived Quality, Image Quality, Light Field Display, Angular Resolution, Subjective Assessment of Visual Quality(/section)1. INTRODUCTION2D displays show the same image to different directions. Drilling down to the pixel level, this is because each pixel shows the same color and intensity to all directions (disregarding intensity falloff at steep angles). However, in case of autostereoscopic 3D displays, emitting different colors to different viewing directions is a required property by principle, as this is the only way to show different images to the two eyes of the human observer without using additional devices for view separation (e.g., glasses). The number of different directions that can be separately controlled and emitted from the display’s surface on a unit angle is referred to as angular resolution. Angular resolution not only determines the quality of the motion parallax effect [1] [2], but it also has a consequence on the depth range of the 3D display.Since continuous motion parallax is an essential quality factor of autostereoscopic 3D displays, it is necessary to provide the given service with an acceptable extent of angular resolution [3]. The motivation of this paper is to extend the knowledge on the perceptual effects of angular resolution, in the aspect of subjective quality perceived from the user’s point of view.Another motivation of this paper is the fact that currently Light Field Displays (LFDs) are far from being common in everyday usage – many people have not even heard about this type of display technology – and the phenomenon of reduced angular resolution is unknown to many. This concern leads to question of validity (or invalidity) regarding subjective results obtained from test participants; the collected subjective data may be inconsistent and misleading.The two main sets of research questions of this paper are the following: (1) How do human observers perceive the changes in angular resolution on LFDs? How much does angular resolution affect the perceptual quality of visual content? What is an acceptable number of views for a given field of view? (2) Can current subjective test participants be considered a reliable source of quality assessment regarding angular resolution? Are subjective scores collected during such evaluations expected to be consistent? Is a simple training phase before subjective assessment sufficient to introduce this new phenomenon to the test participants?The paper is structured as follows: Section 2 provides an overview of the related work. The parameters of the experiment carried out are detailed in Section 3, results of which are presented in Section 4, including a discussion on the validity of the collected data. This is followed by the conclusions of findings in Section 5, also pointing out potential continuations of the work.978-1-5090-5743-6/16/$31.00 ⃝c2016 IEEE
2. RELATED WORKThe Society for Information Display’s (SID) International Display Measurement Standard provides guidelines for measuring parameters such as angular resolution on 3D displays [4]. McIntire investigated the relationship between the amount of disparity and task performance [5]. The maximum amount of disparity that can be presented is directly related to the angular resolution of the display used. High angular resolution could also be achieved by using pico projectors [6], where users directly observe the array of projectors, which are practically functioning as angularly- varying pixels. In such case, angular resolution is affected by the resolution of the projectors. The synthesis of intermediate views can be used to increase angular resolution, as it boosts the number and thus the density of views. Such reconstruction of light field [7] supports smooth motion parallax, however, depending on the solution, the reduced visual quality of the reconstructed image may damage the user experience [8].Beyond angular resolution, several other attributes contribute to the Quality of Experience (QoE) as well. The ratio of the Field of View (FOV) and the number of views displayed in the given FOV determines angular resolution, however, FOV on its own affects QoE [9]. When it comes to resolution, traditional spatial resolution of the source visual content also plays a role in the overall experience of the human observer [10], however, degradations in resolution appear to the user differently as light rays hit the projection- based LFD screen at irregular positions.In the work presented in this paper, angular resolution was the only variable between test conditions. More precisely, the number of views used to display the given visual content varied while the FOV was constant for all test cases.3. RESEARCH CONFIGURATION 3.1. Experimental setupTo investigate our set of research questions, we designed an experiment in which human observers had to assess the quality of still images with varying angular resolution, displayed on a projection-based LFD. We used a 3-meter- wide glasses-free HoloVizio 3D cinema system [11] to present the images to the test participants. The horizontal viewing angle of the selected display was 40 degrees and its brightness was 1500 cd/m2. The subjective quality assessment measurement took place in a closed laboratory environment, with lighting conditions of 25 lx.During the measurement, the test participant viewing and evaluating the stimuli was 4.6 meters away from the display, which was explicitly given by setting up a cord on a straight line (see Figure 1). This was a 2.5H viewing distance [12], as the height of the selected display was 1.8meters. There was also a direct instruction to move along the cord (1 meter in each direction) before evaluating the quality in order to view the displayed images from different angles, and thus observe the continuity of horizontal motion parallax in the process.Fig. 1. Experimental setup of the measurement.A total of 20 test participants (11 men and 9 women) evaluated the quality of the displayed images. The average age of the participants was 26, and they belonged to an age interval running from 19 to 50.3.2. Measurement stimuliAs it was stated earlier in the paper, the only variable of the subjective measurement was angular resolution. This variation was achieved by directly rendering the test stimuli with different number of views. The number of test cases was 10 and each test case was identified by the stimulus’ number of views. The lowest value was 15 and was incremented by 15 until reaching 150, so the test cases were 15, 30, 45, 60 etc. We chose the uniform difference in the number of views between adjacent test cases to be 15 based on the outcomes of measurements prior to the actual experiment, determining it to be above Just Noticeable Difference (JND) for angular resolutions below 3 view/degree for the given display.Three different 3D contents were rendered for the measurement (see Figure 2), and naturally all 3 were rendered 10 times with the given number of views. The stimuli had plain background color and contained an object, complexity of which was different for each. Stimulus A was a collection of shapes with plain colors and clear, sharp edges, stimulus B had fine structural details and stimulus C contained detailed textures. The resolution of the displayed source images was 1024x576. 
 Fig. 2. Stimulus A (top), B (middle) and C (bottom).The reason why we chose to only use still images as source stimuli instead of videos was to exclude perceptual phenomena like frame rate, thus reduce cognitive load and allow a greater focus on the single attribute at hand. Also, rendering the images for the research enabled a precise control over angular resolution. Of course, in future research, we aim to include videos and natural stimuli.The 30 test cases were displayed in a random order, but they were separated by content; first the 10 randomized test cases of source stimulus A were shown to the participants, followed by B and then C. At the beginning of each content sequence, a reference was shown, which was actually test case 150, so the measurement contained a hidden reference for evaluation, because the reference quality was included in the test conditions without the knowledge of the test participants.3.3. Subjective assessment taskThe evaluation of test cases was carried out on an Absolute Category Rating (ACR) scale [13] from 1 to 10, where 1 was the lowest possible score and 10 represented the reference quality. The task was to rate the perceived quality of the displayed objects, focusing on angular resolution. We chose to have an ACR scale larger than the usual 5-point one in order to allow participants distinguish the small differencesbetween adjacent test cases. Degradation Category Rating (DCR) [13] was considered as well during the design of the research, however, we rejected it because of the so-called “wow effect”; test participants are less likely to express annoyance towards new, visually appealing technology. Using a bidirectional comparison scale could also have been an option, but having a complete set of comparison with the gives test conditions would have resulted in a total of 165 comparisons.Before the assessment itself, a learning phase took place, during which test participants were introduced to the measurement task itself, the display, the stimuli and the phenomenon of angular resolution through examples. We only had naïve test subjects; none of the participant had seen light field displays before the measurement, and experiencing changing angular resolution was new to all of them.The test cases were initially displayed for 10 seconds, and the test participants had to assess the quality right after each test case in a time window of 10 seconds, during which the image was still displayed. The duration of the measurement was approximately 11-12 minutes.4. RESULTS4.1. Mean scoresWe expect mean subjective scores to increase along with the number of views, since a higher number of views on a given FOV means higher angular resolution, and thus smoother horizontal motion parallax.Fig. 3. Mean Opinion Scores.The results obtained for the Mean Opinion Score (MOS) of the measurement (see Figure 3) – containing the evaluation of all stimuli, provided by the 20 participants – show a slight inconsistence, due to the fact that test case 75 received a higher mean score than 90, even though this difference appears not to be significant with a 0.95 Confidence Interval 
(CI). Up to test case 75, the differences of adjacent test cases are indeed significant, but not beyond that.The reason why test case 75 was so highly evaluated is a curious case, and more details shall be found if the mean scores of the 3 stimuli are displayed individually (see Figure 4). As it is apparent, the biggest contribution to the aforementioned shape of the overall MOS is due to stimulus C. For test case 75, it has a mean score, which is higher than any other (including the hidden reference), followed by test case 90 with much lower scores (a difference of 1.75), and the 4 test cases after that fluctuate. Stimulus A has a similar tendency regarding test case 75 and 90, but mean scores of test cases with higher numbers of views increase. This increase also applies to stimulus B, however, the phenomenon of inconsistent mean scores is shifted up by 1 test case (90 and 105) and it is also much smaller.Fig. 4. Mean Opinion Scores, separately for each stimulus.The preference of source stimuli can be clearly observed from their mean scores, but this is also reflected in the distribution of scores (see Figure 5). While the most frequent score used to evaluate test stimulus B is 7, it is 8 for A and 9 for C. The distribution is close to uniform on the lower half of the scale, and shows that no unit of the evaluation scale was neglected.Fig. 5. Distribution of scores for each stimulus.4.2. Test case 75, 90 and 105This part of the analysis presents the actual assessment scores obtained by test case 75, 90 and 105 for each source stimulus. In the figures, each cut represents the evaluation of one individual, and the cuts are arranged clockwise by the deviation of these scores.  Fig. 6. Assessment of test case 75, 90 and 105 for stimulus A. Each cut represents the scores of a test participant.In case of stimulus A (see Figure 6), scores appear in many variations of ranking order. 3 participants did not distinguish the perceived quality of these test cases and 6 evaluated two of them equally. Test case 75 was rated the highest, closely followed by test case 105. 8 test participants provided test case 90 lower scores than to the other two. The participant having the highest deviation in these scores gave test case 75 a score of 8, but only 2 to 90 and 10 (score equivalent of reference quality) to 105. We can even observe the opposite of what we would theoretically expect for the quality of the test cases, in a clear, uniform manner (10, 8 and 6 for test case 75, 90 and 105, respectively).  Fig. 7. Assessment of test case 75, 90 and 105 for stimulus B. Each cut represents the scores of a test participant.
The mean score provided for stimulus B is the lowest among the subjective assessment results, however, it can also be said that the scores do not deviate much (see Figure 7). Even though only 2 test participants avoided differentiation in scores completely, the quality of two test cases was rated identical 12 times. Unlike stimulus A, here test case 90 was much appreciated and test case 75 was the least favored.Fig. 8. Assessment of test case 75, 90 and 105 for stimulus C. Each cut represents the scores of a test participant.Compared to the previous two stimuli, stimulus C received clearly higher scores in general (see Figure 8), as can also be seen in the mean scores of the stimuli (see Figure 4). Only a single participant gave the same scores to all 3 test cases, however 10 test participants rated 2 test cases equally. These 10 cases can be clustered into 3 groups: 90 and 105 are the same but 75 is better by 1 unit (2 occurrences), 75 and 105 are the same but 90 is worse by 1 (4 occurrences) and by 2 units (4 occurrences). Test case 75 being the best from these 3 test cases, followed by test case 105 and then 90 is also a popular scoring pattern; 7 test participants assessed accordingly. There are also examples for test case 90 and 105 gaining the highest score, 1 each.4.3. Inconsistent subjective assessments – discussionIn this final part of the results, we intend to address the research question of validity, pointing out a topic – or rather an issue – to the scientific community. Today, at the time of this paper, are test participants truly capable of evaluating a phenomenon like angular resolution? While image resolution is a phenomenon that consumers encounter on a daily basis while for instance watching streaming videos on the Internet, the majority of the people have not even seen autostereoscopic displays in person. In case of our study, 75% of the selected test participants had not even heard of such displays prior to the measurement. The lack of prior knowledge and experience is of course beneficial, since itmay introduce specific types of cognitive bias, e.g., the labelling effect [14]. The role of the training phase is to familiarize the observers with the task and what they will see, but can it be considered to be sufficient to provide consistent, valid results in the end?The 60 rating sequences (20 participants assessed 3 stimuli, and 1 sequence is the series of 10 scores for a given stimulus) are 90% inconsistent, if we in this case define a sequence to be consistent in the following way: for any Vi, Si+n must be greater than or equal to Si, where S is the subjective score allocated to V, which denotes the given number of views, i is the index of a test case and n is an arbitrary positive integer. We hereby present 3 series of inconsistent subjective assessment sequences for each stimulus, provided by different test participants.For stimulus A (see Figure 9), the first sequence might be familiar, since it has already been pointed out earlier (see Figure 6), for having the highest deviation for test case 75, 90 and 105. The other two sequences are similar in this sense, however, in case of the second sequence, it is test case 105 that received a sudden low score compared to the prior test case. These two sequences put together show a radical contrast for test case 90, since – while it obtained the lowest possible score in the third sequence – it was assessed to be an equal of the reference in the second one.Fig. 9. Examples of inconsistent scores for stimulus A.In stimulus B (see Figure 10) the first evaluation sequence determines test case 15 to have the best perceptual quality, even though it displays the content in such a way that not only discrete image borders are visible, but that the adjacent views are also continuously present semi- transparently, regardless of viewing position. The second one has a uniform increase for the first half, however, has a sudden rise and a falling tendency for the second half, except from the hidden reference. The third sequence has a surprisingly high score for test case 45, compared to the  
adjacent scores, followed by score fluctuation from test case 75, and ending in decreasing scores.experiment. The knowledge on this cognitive distortion phenomenon could benefit from further, more exhaustive research.The training phase prior to the subjective assessment of visualized 3D content on such displays evidently affects the performance of test subjects during quality evaluation. Future recommendations, benchmarks and standards particularly considering subjective assessment methods on autostereoscopic 3D displays could additionally benefit the research community by declaring standardized training phases with special concern for such new visual phenomena.The research presented in this paper did not exclude the results of any test participant. Removing outliers may reduce the deviation of the score set and thus increase confidence, however, having numerous distorted score series from the same inconsistent pattern may result in discarding undistorted – or at least less distorted – evaluations, due to their statistical distances from other observations. Also, we kept all the acquired data in the analysis in order to demonstrate the effect of such score sets on the mean values of user experience.One may argue that motion parallax is something that people are used to, as we encounter it in real life. That is indeed unquestionable, however, reductions in angular resolution and thus in the smoothness of motion parallax does not occur in everyday life, making this phenomenon new for those without any prior experience with such display technologies.5. CONCLUSIONSThe paper has presented the results of a subjective quality assessment where test participants rated visual contents displayed on a light field display with different angular resolutions. We found that user experience appears to correlate well with angular resolution, however, our results indicate severe inconsistencies in the ratings provided by the test participants, supporting our questioning of the validity of the results obtained by subjectively evaluating a phenomenon the test participant had not experienced prior to the experiment.The continuation of this work shall focus particularly on video quality, as factors like frame rate may affect the perception of angular resolution. In the future, we also plan to address more subjective quality assessment validity issues that are exclusively present in autostereoscopic 3D displays.ACKNOWLEDGMENTSThe work in this paper was funded from the European Union’s Horizon 2020 research and innovation program under the Marie Sklodowska-Curie grant agreement No 643072, Network QoE-Net. The research leading to these results has received funding from the PROLIGHT-IAPP Marie Curie Action of the People programme of the Fig. 10. Examples of inconsistent scores for stimulus B.The selected sequences of stimulus C (see Figure 11) show assessment inconsistency as well. The first one already reaches the maximal score at test case 45, and it also has the opposite scoring relation for test case 90 and 105, compared to the majority of ratings for this stimulus (see Figure 8). The second and the third evaluation sequence both have score fluctuation beyond test case 105 and the highest score was obtained by test case 75, but the second one has a relatively high score for test case 30, even higher than what was given for test case 90. Fig. 11. Examples of inconsistent scores for stimulus C.From these results, we can conclude that there are indeed returning patterns in inconsistencies – as also seen earlier in the paper, in the comparison of test case 75, 90 and 105 – yet we also need to add that the actual reasons for some specific distortions remain unclear to us after this
European Union’s Seventh Framework Programme, REA grant agreement 32449. The work was also supported by the Department of Networked Systems and Services of the Budapest University of Technology and Economics.(/section)http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823450(/section)@INPROCEEDINGS{7823450, 
author={P. A. Kara and M. G. Martini and P. T. Kovacs and S. Imre and A. Barsi and K. Lackner and T. Balogh}, 
booktitle={2016 International Conference on 3D Imaging (IC3D)}, 
title={Perceived quality of angular resolution for light field displays and the validy of subjective assessment}, 
year={2016}, 
pages={1-7}, 
keywords={image resolution;stereo image processing;three-dimensional displays;angular resolution;autostereoscopic 3D displays;light field displays;motion parallax effect;subjective quality assessment;visual content perceptual quality;visual experience;Atmospheric measurements;Image color analysis;Particle measurements;Spatial resolution;Three-dimensional displays;Visualization;Angular Resolution;Image Quality;Light Field Display;Perceived Quality;Quality of Experience;Subjective Assessment of Visual Quality}, 
doi={10.1109/IC3D.2016.7823450}, 
month={Dec},}