THE EFFECTS OF DEPTH WARPING ON PERCEIVED ACCELERATION IN STEREOSCOPIC ANIMATION(/section)Sidrah Laldin, Laurie M. Wilcox, Robert S. Allison(/section)2016 International Conference on 3D Imaging (IC3D)(/section)Stereoscopic media produce the sensation of depth through differences between the images presented to the two eyes. These differences arise from binocular parallax which in turn is caused by the separation of the cameras used to capture the scene. Creators of stereoscopic media face the challenge of depicting compelling depth while restricting the amount of parallax to a comfortable range. To address this tradeoff, stereoscopic warping or depth adjustment algorithms are used in the post-production process to selectively increase or decrease the depth in specific regions. This process modifies the image’s depth-to-parallax mapping to suit the desired parallax range. As the depth is adjusted using non-linear parallax re-mapping functions, the geometric stereoscopic space is distorted. In addition, the relative expansion or compression of stereoscopic space should theoretically affect the perceived acceleration of an object passing through that region. Here we evaluate this prediction and determine if stereoscopic warping affects viewers' perception of acceleration. Observers judged the perceived acceleration of an approaching object (a toy helicopter) moving in depth through a complex stereoscopic 3D scene. The helicopter flew at one of two altitudes, either ground level or camera level. For each altitude, stereoscopic animations were produced under three depth re-mapping conditions (i) compressive, (ii) expansive, and (iii) zero (no re-mapping) for a total of six test conditions.We predicted that expansive depth re-mapping would produce a bias toward perceiving deceleration of the approaching helicopter, while compressive depth re- mapping would result in a bias toward seeing acceleration. However, there were no significant differences in the amount or direction of bias between the re-mapping conditions. We did find a significant effect of the helicopter altitude, such that there was little bias in acceleration judgements when the helicopter moved at ground level but a significant bias towards reporting acceleration when the helicopter moved at camera level. This result is consistent with the proposal that observers can make use of additional monocular (2D) cues in the ground level condition to improve their acceleration estimates. The lack of an effect ofdepth re-mapping suggests that viewers have considerable tolerance to depth distortions resulting from stereoscopic post-processing. These results have important implications for effective post-production and quality assurance for stereoscopic 3D content creation.(/section)1. INTRODUCTIONDepth from disparity in a stereoscopic image reflects the layout of the scene but is also affected by a number of artistic, on-set production, post-production, and display parameters. A tool that filmmakers often use to determine stereoscopic parameters is the disparity range or parallax budget. This range is usually limited and carefully controlled to ensure comfortable viewing or to respect quality assurance standards. Thus, one of the most important stereoscopic 3D (S3D) filmmaking parameters is the interaxial distance between the two cameras, as it controls the mapping of the range of depths in the scene to the range of parallax in the image. This parallax is usually expressed in terms of the number of pixels of lateral shift between the images of the same object in the left and right camera view, or alternatively the size of this shift as a percentage of the image width. Assuming a ‘typical’ viewing geometry, the parallax budget controls the desired range of retinal disparities that will be presented to the user.In native capture stereoscopic filming, the camera interaxial separation affects the parallax to depth relationship throughout the entire scene. With the single parameter of interaxial, parallax cannot be increased at one range of distances and simultaneously decreased or held constant at another. Once the content has been captured at a particular camera baseline, it is generally not possible to change the interaxial. Furthermore, during capture, the parallax range is typically optimized for a particular screen size; when the footage is subsequently displayed on a screen with a different size, the predicted depth experienced by the audience will change. For example, according to stereoscopic geometry, if a S3D image optimized for a theatre-sized screen is viewed on a small screen (at a nearer978-1-5090-5743-6/16/$31.00 ⃝c2016 IEEEdistance so it subtends the same visual angle) then geometry predicts a decrease in depth and a flattening of objects in the scene. Conversely, an image designed for a small screen can be uncomfortable to view when scaled up. Although S3D content producers have various capturing techniques, such as multi-view acquisition and multiple retakes, at their disposal to adapt the content to different viewing conditions, these methods can be computationally complex, time- consuming, and costly. Content producers can also employ labour intensive tools such as manual editing of disparities by compositing scenes from multiple stereo rigs with varying baselines.To cope with these issues, S3D content producers can use stereoscopic warping or depth adjustment in the post- production phase. This process permits modification of the image’s depth-to-parallax mapping to suit the desired parallax range. In addition, depth-to-disparity modelling is performed such that the parallax can be selectively retargeted for a defined region of interest in the image. This results in modified depth in specific parts of the 3D image leaving the depth in other regions unchanged. This kind of region-defined disparity manipulation is known as non- linear parallax mapping or non-linear disparity mapping by some researchers, and provides the content producers with a robust means to manipulate and control depth in isolated parts of the image for technical and/or artistic reasons [1]– [6].Non-linear depth adjustment can be beneficial when a large range of distances need to be portrayed in a scene that also contains a volumetric object in the foreground. If this scene is shot with a restricted parallax budget, then all depths within the scene will be compressed, and the foreground object may appear significantly compressed and flattened relative to its width. If the depth budget is expanded, to give the foreground object(s) more volume, the director risks introducing too much parallax in the background which may introduce divergence. Region- specific disparity manipulation through non-linear disparity mapping provides a solution as it permits enhancement of the depth of the foreground, while leaving the depth in the background unchanged [2].The non-linear parallax mapping process involves several steps including: (i) generation of parallax or depth maps, (ii) adjustment of the function between zin (distance from the camera in the original stereo pairs) and zout (the geometrically predicted distance from the viewer of the display), and (iii) creation of a new stereoscopic image based on the depth maps and the new zout function. The key element is that the user or 3D content producer can specify the in-out distance or parallax maps based on the desired creative and technical effects. It is a common practice that once the left view has been acquired, the parallax manipulations are performed on the right view based on the nearest and farthest distances, desired parallaxes at these points, and the parallax remapping function between these end points. As the depth is adjusted using non-linearparallax re-mapping functions, the geometrically predicted stereoscopic space is distorted. It no longer adheres to the stereoscopic geometry of the scene that was captured (even if presented orthostereoscopically) or to the monocular depth cues in the perspective images.Typically the input-output parallax mapping functions are monotonic and smooth to avoid reversals or discontinuities in the relationship between parallax and depth (discontinuities can be used if no objects appear at or near the distance of the discontinuity). As noted in the figures that follow, unless they are linear, these monotonic parallax remapping functions produce stereoscopic distortions; depths between the different points of the scene are compressed or expanded depending on their distance. In expansive parallax re-mapping functions, the parallax between objects that are near the camera will be smaller than in the original stereoscopic images, while the parallax will be larger than in the original at far distances from the camera. This predicts a perceived expansion of stereoscopic space with increasing distance from the camera. Conversely, with a compressive parallax re-mapping function, compression of space should increase as distance from the camera increases.As well as affecting static depth intervals, this compression or expansion of stereoscopic space should affect the perceived motion of an object traversing the space. That is, if an object moves in depth relative to the camera at constant velocity in the scene, but the mapping from the original to transformed stereoscopic is compressive or expansive, then the object’s apparent velocity should change over time. If the object moves in the direction in which the space expands then it should appear to accelerate. Conversely, it should appear to decelerate if it moves in the opposite direction.2. METHODS2.1. ParticipantsParticipants (n=7) ranged in age from 19 to 35, had normal or corrected to normal visual acuity, and good stereoscopic vision (at least 40 arcseconds assessed using the Randot Stereotest). Three of the observers were female, four were male, and all were paid for their participation.2.2. StimuliThe scene was constructed in Maya (Autodesk, version 2012) to simulate a realistic animation clip from an S3D movie complete with multiple monocular and binocular depth cues. Each graphic unit in the modelled scene was equivalent to a centimeter in 3D space and thus we will report all dimensions in cm (see below for the effects of image scaling and stereoscopic presentation). The frame rate of the stereoscopic presentation was 24 fps and we will report all durations, speeds and accelerations in seconds based on this frame rate.The shot consisted of a toy helicopter (38.51 cm x 12.85 cm) flying toward the camera across a school gym (604.52 cm by 998.98 cm). The gym included a stage with curtains in the background, multiple rows and columns of chairs placed in the middle of the gym, as well as various other objects placed throughout the space (Figure 1). The only moving object in the scene was the helicopter, which sported a rotor that turned at a constant speed throughout the clip (so as not to provide an extraneous cue for the acceleration or deceleration of the helicopter).In the z-space (depth direction) of the scene, the helicopter moved from a distance of 650 cm to approximately 150 cm. Because the camera was located at z=25 cm this corresponded to a range of 625 cm to 125 cm relative to the camera. The z-axis motion path specified in Maya was a straight line approach trajectory traversing 500 cm. The helicopter covered this distance in 5 s (120 frames) for a simulated average speed of 100 cm/s. This average speed was constant across animations although acceleration, and thus the start and end speed varied.Fig. 1. Helicopter shot / gym scene used in the experiments. The helicopter is approaching at floor level in this image.Fig. 2. The helicopter approaching at eye level.The position of an object relative to the ground plane is a strong monocular depth cue (called ‘height in the field’). Further, changing the altitude of the object will influence the availability, and influence of, monocular depth cues. Thus we evaluated whether the height of the helicopter above the ground had an impact on the viewer’s perception of acceleration or deceleration. To do so we compared two‘altitude’ conditions: one where the simulated helicopter flew just above the ground and one where it approached at camera height (43.7 cm). In the latter case the helicopter remained at the same vertical position in the image as it approached, making the height in the field cues uninformative (Figure 2).In all the conditions, the start position of the helicopter was at 625 cm from the camera and the end position was at 125 cm from the camera in the world z-coordinates (i.e., separation in depth along the floor). However, the camera was pitched downward (-3.34o) in the floor level condition for better framing. This resulted in slight differences in distances along the camera z-direction of the start and end positions of the helicopter between the two conditions That is, they were slightly further from the camera (+4 cm) in the ground level condition than in the camera level condition.Stereoscopic animations were rendered as separate left and right eye views. It was critical to maintain constant parallax at the start and end position of the helicopter throughout all the test conditions. In these experiments the effective unwarped stereoscopic camera rig had parallel cameras with focal length of 35 mm (35-mm equivalent, 54o horizontal field of view) and an interaxial separation of 1.98 cm. The rig was converged (using standard off-axis/skew frustrum stereoscopic rendering) at 125 cm from the camera so that the animation stopped as the nose of the helicopter reached the screen plane (i.e., had zero screen parallax). Based on these parameters, the parallax at the start position for the ground level was 25.92 pixels and for the eye-level condition was 23.92 pixels across all test conditions. The end disparity of the front tip of the helicopter was zero in all conditions.The non-linear parallax remapping was accomplished based on the rendered camera frames and associated depth maps using Fusion (Blackmagic Design, version 6.3). Based on the input images, and the desired parallax remapping, a new right camera image sequence was rendered. The disparities at the start and end position of the helicopter’s travel were controlled and maintained in Fusion and were verified by comparison with onscreen disparity. In the stereoscopic tools in Fusion, a near and far point can be associated with a range of parallax values (parallax budget) and the desired interaxial distance computed. These values were set to match the stereoscopic rig parameters listed in the previous paragraph.2.3. Non-linear parallax re-mappingThree non-linear parallax re-mapping functions were used for this study. The parallaxes at both the start (z = 650) and end (z = 150) positions of the helicopter were constant across all conditions and the parallax at these points corresponded to the distance in the modelled scene and the stereoscopic rig parameters. To remap the depth of the selected scene, to the space between these end points (i.e. along the path traversed by the helicopter) the relationship between distance in the modelled scene and the parallax   specified distance was mapped according to one of three quadratic functions. These functions describe the relationship between the original z position of the helicopter in the modelled scene (zin) and the z position specified by the screen parallax after mapping (zout) (Refer to Figure 3 below):1. Linear:   =   In the linear condition the       stereoscopic parallax matches the perspective depth. The correspondence is appropriate for the camera baseline and this parallax is not manipulated in the post-production. Note, however, that the stereoscopic camera baseline is smaller than the observer’s eye separation so the predicted stereoscopic depth for the whole scene is somewhat compressed relative to the modelled scene. This stereoscopic distortion in the scene is the natural result of the camera set up and parameters and is typical for stereoscopic movies.Fig. 3. Non-linear parallax remapping function. Parallax for zin values (x-axis) were remapped to parallax appropriate to a different zout (y-axis).2.4. Stereoscopic Display and Viewing2. C  ompressive function:      =− .        +  .     −    . ,     ≤   ≤    The stimuli were displayed on 54-inch 1080p Panasonic Viera Series TC-P54VT25 3DTV plasma television with dimensions of 119.8 (W) and 67.3 (H) cm and pixel resolution of 1920 (W) and 1080 (H). The stereoscopic images were viewed through active shutter glasses provided with the television. The position of the viewer relative to the screen was adjusted to obtain a horizontal viewing angle of 36 degrees (1.8m from screen). The viewer sat stationary throughout the session.The camera interaxial separation was smaller than the viewer’s interocular distance (which averaged 5.81 cm as measured with a Reichert, Digital PD Meter). Additionally, the CG camera field of view was wider than the display visual angle. These factors are typical of filmed stereoscopic content in commercial productions where lens and interaxial choices are made for reasons of artistic preference and visual comfort rather than to match a specific viewer and viewing position (which is impossible in a theatre setting).2.5. ProcedureThe method of constant stimuli was used to assess the perceived acceleration/deceleration of the helicopter under each of the disparity mapping and altitude conditions. For each condition, stimuli with 11 levels of acceleration were presented to cover a range of positive and negative accelerations. A set of pilot experiments determined an appropriate range of accelerations needed to adequately sample the psychometric functions (Table 1). On each trial, the observer viewed one helicopter trajectory, and indicated verbally whether the helicopter appeared to be accelerating or decelerating. Each stimulus condition was presented 20 times over 10 sessions (2 repeats per session). For each subject, the proportion of accelerating responses at each stimulus level was tabulated and psychometric functions were fit using a Weibull function. From each psychometric function we estimated the point of subjective equality (PSE) for each mapping function. The PSE in the present case is            , otherwisewhere stereoscopic depth intervals are compressed relative to the model at distances far from the camera. Given that the object moves towards the camera (z-values decrease) the object should appear to accelerate as it approaches (relative to the linear case). As the helicopter covers the same distance (end points are fixed) in the same time average simulated velocity remains 100 cm/s. However, the velocity changes with a simulated acceleration of 24.8 cm/s2, starting from 38 cm/s at z = 650 and increasing to 162 cm/s at z = 150.3. E xpansive function:      = .        +  .     +    . ,     ≤   ≤                , otherwisewhere stereoscopic depth intervals are expanded relative to the model at distances far from the camera. Since the object moves towards the camera it should appear to decelerate (relative to the linear case). The simulated deceleration is 24.8 cm/s2, starting from 162 cm/s at z = 650 and decreasing to 38 cm/s at z = 150.Care was taken so that the rate of change of depth was either strictly increasing or decreasing over the manipulated trajectory (z-values between 650 cm and 150cm). In Fusion, disparity manipulation occurs at the nodal level, in which a node is created to specify how the z-value is manipulated. Thus, the three zin versus zout relations were generated over the range of relevant z values (Figure 3). the stimulus level at which the participant is equally like to report that the helicopter was accelerating or decelerating (the 50% point on the psychometric function). Bias predictions were calculated using each observer’s interocular distance. If the re-mapping biases the apparent acceleration in one direction, then the PSE should be shifted in the opposite direction since acceleration in the opposite direction is needed to null this bias.    Acceleration (cm/frame2)Acceleration (cm/s2) Initial velocity (cm/s)   Final velocity (cm/s)  0.0528.8 30.0  172.8  0.0423.04 44.3  158.6  0.0317.28 58.6  144.3  0.0211.52 72.9  130.0  0.015.76 87.2  115.7  00 101.4  101.4  -0.01-5.76 116.4  87.8  -0.02-11.52 130.7  73.5  -0.03-17.28 144.9  59.3  -0.04-23.04 159.2  45.0 -0.05-28.8  173.5 30.7            Table 1. Acceleration levels used to measure the effects of non-linear parallax remapping.3. RESULTS AND DISCUSSIONFigure 4 shows sample psychometric functions for one observer for the linear, compressive, and expansive non- linear parallax re-mapping conditions. As expected, as acceleration increases from negative to positive, the proportion of positive acceleration responses increases. The observer in Figure 4 demonstrates bias that is dependent on the remapping function. Once again, it should be noted that the predicted PSE (50% point on the fitted curve) is opposite in direction to the bias because oppositely directed acceleration will be needed to cancel the bias. For example, in Figure 4, the observer was biased to perceive the stimulus as accelerating for the compressive function; however, because the PSE reflects the amount of acceleration needed to cancel the positive bias, the PSE value is negative.Fig. 4. Sample psychometric functions (fit with Weibull functions) for one subject for each mapping condition (compressive, linear and expansive) of the ground condition.The average PSEs for all participants are shown in Figure 5 as a function of the non-linear parallax remapping condition and altitude. This figure also depicts the geometrically predicted PSE values based on the stereoscopic geometry.Fig. 5. Average PSE values for Eye (Camera) Level and Ground Level conditions. The lines show predicted PSE values for each remapping curve with compressive at -13.9, linear at -7.9, and expansive at -4.2 cm/s2We predicted that the transition points would vary as a function of non-linear parallax remapping algorithm. Furthermore, when the stereoscopic capture parameters differ from the viewing parameters (as in this study and in most filmed content) geometry predicts a transformation between the geometry of the modeled scene and its appearance in the perceptual display space (Allison, 2004; Woods, 1993). In the current scenario the differences in baseline and magnification predict a nonlinear compression of space relative to the original scene. As a result of the nonlinearity, we would predict—based on parallax alone— that an object moving at constant velocity in depth would appear to be accelerating at 7.9 cm/s2. The acceleration predictions for our compressive and expansive re-mappingswould also be subject to this compression and hence biased toward acceleration with predicted accelerations of 13.9 and 4.2 cm/s2, respectively.It is clear that these predictions were not borne out. A repeated-measures ANOVA confirmed that while there was a significant main effect of altitude (F(1,35)=37.438, p= 5.39e-07), there was no effect of depth warping on perceived acceleration (F(2,35)=0.857, p=0.433). The interaction between depth warping and the altitude of the helicopter was also not significant (F(2,35)= 0.046, p=0.955).The impact of helicopter altitude on perceived acceleration is evident in Figure 5. That is, in the ground level condition there was little bias, while in the camera level condition, there was a significant bias toward seeing the helicopter accelerate (deceleration was required to null the bias). This altitude-dependent bias was consistent across the non-linear parallax re-mapping conditions.In summary, the results of the experiment show that although participants’ perception of the transition between perceived acceleration and deceleration differed significantly as a function of helicopter altitude, there was no consistent effect of stereoscopic depth warping at either altitude.The S3D scene contained monocular cues such as looming, perspective, and distance from the horizon in addition to the screen parallax. To isolate the effect of the monocular cues and their influence on perceived motion through the scene we replicated the main experiment but with monocular viewing of the linear mapping stimulus (with non-dominant eye patched) in three participants. We found no significant differences in PSE between eye level and ground condition when viewed monocularly. Two participants displayed bias towards seeing the helicopter accelerate, while the other was biased toward seeing deceleration. The bias toward acceleration was consistent with the results of the main experiment, thus confirming that monocular cues may have played a role in the perception of acceleration in the first experiment.4. GENERAL DISCUSSIONThe three main cues to motion-in-depth that have been studied in the literature are target vergence (absolute screen parallax of the helicopter in our study), relative disparity (difference in parallax, or relative parallax, between the helicopter and other stationary features), and changing image size / looming (here looming of the helicopter). One of the earliest studies done on this topic was by Regan and Beverly in 1979. Their experiments investigated the rate of change in disparity that was needed to null perceived motion in depth due to changing target size [8]. They determined that the contribution of disparity to motion in depth perception becomes more pronounced when either velocity or presentation times are increased. Subsequent studies have investigated the added role of target vergence, in addition torelative parallax and looming in perception of motion in depth.For instance, Brenner et al. [9] presented targets with simulated motion in depth based on various combinations of changing absolute screen parallax, changing relative parallax (presence or absence of other stationary features), and looming. Their participants adjusted the lateral velocity of a subsequently presented probe to match the target’s speed of motion in depth. Matched lateral velocity was always less than the simulated motion-in-depth velocity. Changing screen parallax (target vergence) alone did not produce motion in depth (see also [10]) but could influence the matches when other cues were also presented. This suggests that target vergence alone was insufficient to produce motion in depth but could modulate it. Compared to our stimuli, the monocular cues to distance in these displays were minimal. Nevertheless, looming produced the most robust motion in depth and, somewhat unexpectedly as it was ambiguous to absolute distance, image size affected perceived target distance. Changing the screen parallax of the target, relative to static features, produced motion in depth although it was reduced relative to that experienced in the full cue or looming only conditions. Others have shown that the perceptual interpretation of the binocular cues depends on the strength of monocular looming cues. The latter can modulate the magnitude and even the direction of the perceived motion in depth [11], [12].Compared to these previous studies, in Experiment 1, rich monocular and binocular cues were available to specify the depth of the helicopter relative to the rest of the scene. Further, changing screen parallax was always accompanied by changing relative parallax. The absolute screen parallax of the helicopter at any time was nonlinearly mapped according to the depth remapping and thus the apparent motion due to target vergence should have manifested the predicted accelerations and decelerations.Predictions based on relative parallax are more complicated. Relative to the unwarped distant background (or near foreground), the changing relative parallax of the helicopter was distorted in the same manner as the absolute parallax and thus we would predict acceleration and deceleration of the helicopter under parallax re-mapping. However, note that the entire scene was also subject to the same parallax re-mapping as the helicopter. Therefore, during the motion both the path of the helicopter and the space it moved through were stereoscopically distorted and thus the distortion of local relative parallax was small, particularly for the floor altitude condition. In fact, any object stereoscopically aligned with the helicopter at a given frame in the linear animation would also be aligned with helicopter at the corresponding frame in the re-mapped animations. Thus when comparing the parallax (and predicted relative stereoscopic depth) of the helicopter over time relative to features at similar depth (say on the floor), the progress of the helicopter over the space should be identical regardless of the warping. In this case thedistortion of the motion path of the helicopter might depend on the distortion (or lack of) of the depth in the scene itself.We have some evidence that in the presence of strong perspective and other monocular cues such distortions may be minimal. Previous studies on the effect of interaxial separation on perception of stereoscopic depth have shown that observers have a surprising ability to tolerate a wide range of interaxial settings without significant distortion [13]. If the apparent depth and shape of the scene were unperturbed by the re-mapping then we would predict that observer would not see the acceleration expected if the space was apparently distorted. McKee and Welch [14] have demonstrated that observers have poor ability to scale velocity for distance (velocity constancy) compared to size or depth. Therefore, even if stereoscopic space appeared distorted it may not have been evident in the motion profile of the helicopter.Another important aspect of motion in depth studies related to our experiments is the observers’ ability to perceive acceleration in moving objects. In an earlier study we assessed whether asymmetric distortion in the mapping of stereoscopic to real space as a result of varying interaxial has impact on the perceived acceleration of an object moving through that space under orthostereoscopic viewing [15]. Our data suggested that observers were able to discount distortions of stereoscopic space in interpreting object acceleration / deceleration [15]. Other previous work has suggested that observers are relatively insensitive to 2D or 3D acceleration. Gottsdanker, Frick, and Lockard [16] asked subjects to discriminate between accelerated and constant-velocity moving targets. They found that performance improved as mean velocity of the object increased, and presentation time decreased. They concluded, as did subsequent studies [17], that rather than being perceived directly, acceleration was detected by comparing early and late velocities. Later studies have shown that observers often misperceive acceleration resulting in overestimation times of arrival time in time-to-contact experiments [18], although the bias was reduced when binocular information was present. More recent studies have demonstrated that observers have high thresholds and systematic biases when judging acceleration based on image looming [19]. This general lack of sensitivity to acceleration of moving objects may underlie the lack of an influence of depth remapping on apparent acceleration that we found in the present study. However, we note that observers were able to discriminate acceleration in our stimuli (Figure 4). The just noticeable differences in the psychometric functions were considerably smaller than the predicted effects of the nonlinear disparity remapping. Thus, participants should been sensitive to the predicted effects of the remapping.In contrast to the lack of an effect of parallax remapping we did find a significant effect of altitude. The small biases seen in the ground level condition suggests that observers were using ground plane cues in these judgements. Asnoted above, any factor that influences perceived distance should impact the perceived acceleration of an object traversing through that distance. The importance of the ground surface in determining the perceived distance of objects in 3D scenes was noted by Alhazen about 1000 years ago [20]. Much later, Gibson [21] highlighted the importance of the ground surface in perception of 3D scenes. One aspect is the so-called height in the visual field, which reflects the geometric relation between distance and height in the optic array. As the horizon lies at eye level, everything on the ground is projected onto the lower half of the optic array [22]. As the distance from the observer increases, so does the height in the optic array. More recent research by Bian and colleagues [23] has posited a ground dominance effect in determining the perceived relative distances of objects in 3D scenes. They found that when presented with vertical posts in optical contact with either the ground or the ceiling, the observers perceived the one attached to ground surface to be closer.The increased accuracy of acceleration judgements at ground level compared to eye level that we found is similar to improvements in other judgements when ground contact information was available. For example, Philbeck et al. compared walking and verbal report as indicators of distance with angular elevation (eye-level vs. ground level) as a variable. They found that adding height in the field as a distance cue (moving the target from eye-level to ground level) improved the accuracy of walked distance, thus providing evidence of angular elevation as an effective cue to egocentric distance [24].Our study has important implications for both content production and quality assurance of stereoscopic 3D media. Content producers face the challenge of increasing depth and maintaining the parallax budget, thus depth warping has become a popular and effective tool. Our research shows that observers have significant tolerance to parallax re- mapping; they generally are not sensitive to the differences in motion that theoretically result from re-mapping functions.5. ACKNOWLEDGEMENTSThis work was supported by grants to the 3DFlic project from the Ontario Media Development Corporation and the Ontario Centres of Excellence. Thanks to Rob Burton and Arc Productions for expert advice and assistance with the preparation of the stimuli. Also, thanks to Carly Hylton for help with the data collection.(/section)http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823446(/section)@INPROCEEDINGS{7823446, author={S. Laldin and L. M. Wilcox and R. S. Allison}, booktitle={2016 International Conference on 3D Imaging (IC3D)}, title={The effects of depth warping on perceived acceleration in stereoscopic animation}, year={2016}, pages={1-8}, keywords={cameras;image coding;image sensors;object detection;optical distortion;stereo image processing;binocular parallax;camera level;geometric stereoscopic space distortion;helicopter altitude;image depth-to-parallax mapping;nonlinear parallax re-mapping functions;object detection;quality assurance;stereoscopic 3D scene capture;stereoscopic animation;stereoscopic depth adjustment algorithms;stereoscopic depth warping algorithms;stereoscopic post-processing;stereoscopic space compression;stereoscopic space expansion;Acceleration;Animation;Cameras;Helicopters;Nonlinear distortion;Stereo image processing;Three-dimensional displays;acceleration;depth warping;motion in depth;stereoscopic 3D media}, doi={10.1109/IC3D.2016.7823446}, month={Dec},}